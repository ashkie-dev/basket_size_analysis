{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from pandarallel import pandarallel\n",
    "# import concurrent.futures\n",
    "# from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "# from urllib.parse import urlparse\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# from natsort import natsorted, ns\n",
    "import glob\n",
    "import pydash as dash\n",
    "# import rapidfuzz as fuzz\n",
    "# from rapidfuzz.process import extractOne\n",
    "# from rapidfuzz.string_metric import levenshtein, normalized_levenshtein\n",
    "# from rapidfuzz.fuzz import ratio\n",
    "# from rapidfuzz import utils as fuzz_utils\n",
    "import itertools as it\n",
    "# import tfidf_matcher as matcher\n",
    "from ftfy import fix_text\n",
    "# from textblob import TextBlob, Word, Blobber\n",
    "# from collections import namedtuple, defaultdict, deque\n",
    "\n",
    "pandarallel.initialize(progress_bar=False, verbose=1)\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "# pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.min_rows', 30)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "# pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = pd.read_excel('infiles/odoo_orders_all.xlsx', sheet_name='update')\n",
    "# df_in = pd.read_csv('/Users/ash/Downloads/orders_export.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_in.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79826, 4)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze(*args, **kwargs):\n",
    "#     \"\"\"\n",
    "#     analyze creates basket analysis with support and lift metrics\n",
    "#     Arguments:\n",
    "#     [\n",
    "#         args[0] = DataFrame,\n",
    "#         args[1] = Invoice or Order Id,\n",
    "#         args[2] = Barcode, or Comparible Basket Item\n",
    "#         args[3] = Quantity sold of each item within each order\n",
    "#     ]\n",
    "#     \"\"\"\n",
    "\n",
    "#     def encodeUnits(x):\n",
    "#         if x <= 0:\n",
    "#             return 0\n",
    "#         if x >= 1:\n",
    "#             return 1\n",
    "\n",
    "#     def format_data(*args):\n",
    "#         if type(args[1]) == list:\n",
    "#             df = (args[0].groupby([args[1][1], args[1][2]])[args[1][3]].sum().unstack().reset_index().fillna(0).set_index(args[1][1]))\n",
    "#             print('yes')\n",
    "#         else:\n",
    "#             print(print(args[1][1]))\n",
    "#             df = (args[0].groupby([args[1][1], args[1][2]])[args[1][3]].sum().unstack().reset_index().fillna(0).set_index(args[1][1]))\n",
    "\n",
    "#         df_enc = df.parallel_applymap(encodeUnits)\n",
    "#         df_enc_plus = df_enc[(df_enc > 0).sum(axis=1) >= 2]\n",
    "#         return df_enc_plus\n",
    "#     def apply_apriori(df, **kwargs):\n",
    "#         bk = apriori(df, min_support=kwargs.get('min_support', 0.002), use_colnames=True).sort_values('support', ascending=False).reset_index(drop=True)\n",
    "\n",
    "#         assoc = association_rules(bk, metric='lift', min_threshold=1).sort_values(by='lift', ascending=False).reset_index(drop=True)\n",
    "#         assoc[['antecedents', 'consequents']] = assoc[['antecedents', 'consequents']].applymap(lambda x: ', '.join(x))\n",
    "\n",
    "#         return assoc\n",
    "\n",
    "#     basket = format_data(*args)\n",
    "#     bk_df = apply_apriori(basket)\n",
    "#     return bk_df\n",
    "\n",
    "# def formatDF(*args, **kwargs):\n",
    "#     col_names = ['Name', 'Lineitem sku', 'Lineitem name', 'Lineitem quantity']\n",
    "#     df = args[0]\n",
    "#     df_out = df[col_names].copy()\n",
    "\n",
    "#     df_out['Name'] = df_out['Name'].astype(str)\n",
    "#     df_out['Lineitem quantity'] = df_out['Lineitem quantity'].astype(np.int32)\n",
    "#     return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    analyze creates basket analysis with support and lift metrics\n",
    "    Arguments:\n",
    "    [\n",
    "        args[0] = DataFrame,\n",
    "        args[1] = Invoice or Order Id,\n",
    "        args[2] = Barcode, or Comparible Basket Item\n",
    "        args[3] = Quantity sold of each item within each order\n",
    "    ]\n",
    "    \"\"\"\n",
    "\n",
    "    def encodeUnits(x):\n",
    "        if x <= 0:\n",
    "            return False\n",
    "        if x >= 1:\n",
    "            return True\n",
    "\n",
    "    def format_data(*args):\n",
    "        cols = args[0].columns.to_list()\n",
    "        df = args[0].copy()\n",
    "        df[cols[3]] = df[cols[3]].astype(float)\n",
    "        df = (args[0].groupby([cols[0], cols[1]])[cols[3]].sum().unstack().reset_index().fillna(0).set_index(cols[0]))\n",
    "        df_enc = df.parallel_applymap(encodeUnits)\n",
    "        df_enc_plus = df_enc[(df_enc > 0).sum(axis=1) >= 2]\n",
    "        return df_enc_plus\n",
    "    \n",
    "    def apply_apriori(df, **kwargs):\n",
    "        bk = apriori(df, min_support=kwargs.get('min_support', 0.002), use_colnames=True).sort_values('support', ascending=False).reset_index(drop=True)\n",
    "\n",
    "        assoc = association_rules(bk, metric='lift', min_threshold=1).sort_values(by='lift', ascending=False).reset_index(drop=True)\n",
    "        assoc[['antecedents', 'consequents']] = assoc[['antecedents', 'consequents']].applymap(lambda x: ', '.join(x))\n",
    "\n",
    "        return assoc\n",
    "\n",
    "    basket = format_data(*args)\n",
    "    bk_df = apply_apriori(basket)\n",
    "    return bk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk = analyze(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def formatDF(*args, **kwargs):\n",
    "    col_names = ['Name', 'Lineitem sku', 'Lineitem name', 'Lineitem quantity']\n",
    "    df = args[0]\n",
    "    df_out = df[col_names].copy()\n",
    "\n",
    "    df_out['Name'] = df_out['Name'].astype(str)\n",
    "    df_out['Lineitem quantity'] = df_out['Lineitem quantity'].astype(np.int32)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeUnits(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "\n",
    "def format_data(*args):\n",
    "    # cols = ['orderId', 'stockCode', 'items', 'itemQty']\n",
    "    cols = args[0].columns.to_list()\n",
    "    df_pre = args[0].copy()\n",
    "    df_pre[cols[3]] = df_pre[cols[3]].astype(float)\n",
    "    df = (df_pre.groupby([cols[0], cols[1]])[cols[3]].sum().unstack().reset_index().fillna(0).set_index(cols[0]))\n",
    "    # df = (args[0].groupby([cols[0], cols[1]])[cols[2]].sum().unstack().reset_index().fillna(0).set_index(cols[1]))\n",
    "    \n",
    "    df_enc = df.parallel_applymap(encodeUnits)\n",
    "    df_enc_plus = df_enc[(df_enc > 0).sum(axis=1) >= 2]\n",
    "    return df_enc_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.to_list()\n",
    "df['itemQty'] = df['itemQty'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df.groupby([cols[0], cols[1]])[cols[3]].sum().unstack().reset_index().fillna(0).set_index(cols[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gr = df.groupby([cols[0], cols[1]])[[cols[3]]].parallel_apply(lambda x: np.sum(x)).unstack().reset_index().fillna(0).set_index(cols[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['stockCode'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [92], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# main = analyze(df, df.columns, min_support=0.002)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m main \u001b[39m=\u001b[39m format_data(df)\n",
      "Cell \u001b[0;32mIn [90], line 11\u001b[0m, in \u001b[0;36mformat_data\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m      9\u001b[0m cols \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mto_list()\n\u001b[1;32m     10\u001b[0m df_pre \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 11\u001b[0m df \u001b[39m=\u001b[39m (df_pre\u001b[39m.\u001b[39;49mgroupby([cols[\u001b[39m0\u001b[39;49m], cols[\u001b[39m1\u001b[39;49m]])[cols[\u001b[39m2\u001b[39;49m]]\u001b[39m.\u001b[39;49msum()\u001b[39m.\u001b[39;49munstack()\u001b[39m.\u001b[39;49mreset_index()\u001b[39m.\u001b[39;49mfillna(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mset_index(cols[\u001b[39m1\u001b[39;49m]))\n\u001b[1;32m     12\u001b[0m \u001b[39m# df = (args[0].groupby([cols[0], cols[1]])[cols[2]].sum().unstack().reset_index().fillna(0).set_index(cols[1]))\u001b[39;00m\n\u001b[1;32m     14\u001b[0m df_enc \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mparallel_applymap(encodeUnits)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/nlp_venv_3.10.2/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/nlp_venv_3.10.2/lib/python3.10/site-packages/pandas/core/frame.py:5503\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   5500\u001b[0m                 missing\u001b[39m.\u001b[39mappend(col)\n\u001b[1;32m   5502\u001b[0m \u001b[39mif\u001b[39;00m missing:\n\u001b[0;32m-> 5503\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of \u001b[39m\u001b[39m{\u001b[39;00mmissing\u001b[39m}\u001b[39;00m\u001b[39m are in the columns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5505\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   5506\u001b[0m     frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['stockCode'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# main = analyze(df, df.columns, min_support=0.002)\n",
    "main = format_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "argys = ['orderId', 'stockCode', 'items', 'itemQty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['itemQty'] = df['itemQty'].astype(np.int32)\n",
    "df['orderId'] = df['orderId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = df.pop('items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    analyze creates basket analysis with support and lift metrics\n",
    "    Arguments:\n",
    "    [\n",
    "        args[0] = DataFrame,\n",
    "        args[1] = Invoice or Order Id,\n",
    "        args[2] = Barcode, or Comparible Basket Item\n",
    "        args[3] = Quantity sold of each item within each order\n",
    "    ]\n",
    "    \"\"\"\n",
    "\n",
    "    def encodeUnits(x):\n",
    "        if x <= 0:\n",
    "            return 0\n",
    "        if x >= 1:\n",
    "            return 1\n",
    "\n",
    "    def format_data(*args):\n",
    "        df = (args[0].groupby([args[1], args[2]])[args[3]].sum().unstack().reset_index().fillna(0).set_index(args[1]))\n",
    "        df_enc = df.parallel_applymap(encodeUnits)\n",
    "        df_enc_plus = df_enc[(df_enc > 0).sum(axis=1) >= 2]\n",
    "        return df_enc_plus\n",
    "\n",
    "    def apply_apriori(df, **kwargs):\n",
    "        bk = apriori(df, min_support=kwargs.get('min_support', .002), use_colnames=True).sort_values('support', ascending=False).reset_index(drop=True)\n",
    "        assoc = association_rules(bk, metric='lift', min_threshold=1).sort_values(by='lift', ascending=False).reset_index(drop=True)\n",
    "        assoc[['antecedents', 'consequents']] = assoc[['antecedents', 'consequents']].applymap(lambda x: ', '.join(x))\n",
    "        return assoc\n",
    "\n",
    "    basket = format_data(*args)\n",
    "    bk_df = apply_apriori(basket)\n",
    "    return bk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket = analyze(df, 'orderId', 'stockCode', 'itemQty', min_support=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeUnits(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "\n",
    "\n",
    "bkt = (df.groupby(['orderId', 'stockCode'])['itemQty'].sum().unstack().reset_index().fillna(0).set_index('orderId'))\n",
    "bkt.info()\n",
    "bkt_enc = bkt.parallel_applymap(encodeUnits)\n",
    "bkt_enc.head()\n",
    "bkt_enc_plus = bkt_enc[(bkt_enc > 0).sum(axis=1) >= 2]\n",
    "# from apyori import apriori as apy\n",
    "# freq_itms = apriori(bkt_enc_plus, min_support=.0030, use_colnames=True).sort_values('support', ascending=False).reset_index(drop=True)\n",
    "freq_itms_two = apriori(bkt_enc_plus, min_support=.0020, use_colnames=True).sort_values('support', ascending=False).reset_index(drop=True)\n",
    "# rules= apy(bkt_enc_plus, min_support=0.0045, min_confidence=0.2, min_lift=3, min_length=2)\n",
    "# assoc_rules = list(rules)\n",
    "# assoc_rules\n",
    "\n",
    "# freq_itms['length'] = freq_itms['itemsets'].apply(lambda x: len(x))\n",
    "freq_itms_two['length'] = freq_itms_two['itemsets'].apply(lambda x: len(x))\n",
    "\n",
    "assoc = association_rules(freq_itms_two, metric='lift', min_threshold=1).sort_values(by='lift', ascending=False).reset_index(drop=True)\n",
    "assoc[['antecedents', 'consequents']] = assoc[['antecedents', 'consequents']].applymap(lambda x: ', '.join(x))\n",
    "assoc.shape\n",
    "from natsort import natsorted\n",
    "assoc.insert(2, 'pairs', np.nan)\n",
    "# assoc['dupes'] = assoc.loc[assoc[['antecedents', 'consequents']].apply(lambda x: natsorted(list(x)), axis=1).duplicated(keep=False)] #.sort_values(by=['antecedents', 'consequents'], ascending=[True, False]) #.duplicated(subset=['antecedents', 'consequents'])\n",
    "assoc['pairs'] = assoc[['antecedents', 'consequents']].apply(lambda x: natsorted(list(x)), axis=1)\n",
    "assoc['pairs'] = assoc['pairs'].str.join(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    analyze creates a basket analysis\n",
    "    args[str] = [\n",
    "        args[00] = Invoice # or Order Id,\n",
    "        args[01] = Sku, Barcode, or Comparible Data\n",
    "    ]\n",
    "    \"\"\"\n",
    "    df = (args[0].groupby(['orderId', 'stockCode'])['itemQty'].sum().unstack().reset_index().fillna(0).set_index('orderId'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = assoc.sort_values(by=['lift', 'confidence'], ascending=[False, False]).drop_duplicates(subset='pairs', ignore_index=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('infiles/odoo_order_results.xlsx', mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "    af.to_excel(writer, index = False, sheet_name='results_002_noDupes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assoc[['antecedents', 'consequents']].apply(list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv_3.10.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7efae1acedd88cd118124501b75fa0b4df8b6db6dce92a9c027c96f5022d1a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
